{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f22e5d77",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\miniconda3\\envs\\cs175\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n",
            "model: microsoft/deberta-v3-small\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from dataclasses import dataclass\n",
        "from functools import lru_cache\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = \"microsoft/deberta-v3-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(\"device:\", DEVICE)\n",
        "print(\"model:\", MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1e081922",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor, special_tokens_mask=None) -> torch.Tensor:\n",
        "    mask = attention_mask.bool()\n",
        "    if special_tokens_mask is not None:\n",
        "        mask = mask & (~special_tokens_mask.bool().to(mask.device))\n",
        "    if mask.sum() == 0:\n",
        "        mask = attention_mask.bool()\n",
        "    x = last_hidden_state[0][mask[0]]\n",
        "    return x.mean(dim=0)\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=10000)\n",
        "def embed_phrase(phrase: str) -> torch.Tensor:\n",
        "    phrase = phrase.strip().lower()\n",
        "    inputs = tokenizer(\n",
        "        phrase,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=32,\n",
        "        return_special_tokens_mask=True,\n",
        "    )\n",
        "    special_tokens_mask = inputs.pop(\"special_tokens_mask\", None)\n",
        "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "    if special_tokens_mask is not None:\n",
        "        special_tokens_mask = special_tokens_mask.to(DEVICE)\n",
        "    vec = _mean_pool(out.last_hidden_state, inputs[\"attention_mask\"], special_tokens_mask).float().cpu()\n",
        "    return vec / (vec.norm(p=2) + 1e-12)\n",
        "\n",
        "\n",
        "def rank_candidates_by_similarity(triple: list[str], candidates: list[str]) -> list[str]:\n",
        "    triple_vecs = [embed_phrase(w) for w in triple]\n",
        "    centroid = torch.stack(triple_vecs, dim=0).mean(dim=0)\n",
        "    centroid = centroid / (centroid.norm(p=2) + 1e-12)\n",
        "\n",
        "    scored = []\n",
        "    for w in candidates:\n",
        "        v = embed_phrase(w)\n",
        "        scored.append((float(torch.dot(centroid, v)), w))\n",
        "\n",
        "    scored.sort(key=lambda t: t[0], reverse=True)\n",
        "    return [w for _, w in scored]\n",
        "\n",
        "\n",
        "def leave_one_out_queries(words4: list[str]) -> list[dict]:\n",
        "    if len(words4) != 4:\n",
        "        return []\n",
        "    out = []\n",
        "    for i in range(4):\n",
        "        answer = words4[i]\n",
        "        triple = [words4[j] for j in range(4) if j != i]\n",
        "        out.append({\"triple\": triple, \"answer\": answer, \"candidates\": list(words4)})\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "99823e13",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "def load_connections_from_hf(split: str = \"train\"):\n",
        "    \"\"\"Load NYT Connections from Hugging Face (tm21cy/NYT-Connections) and return a split.\n",
        "\n",
        "    The split has columns like: date, contest, words (16), answers (4 groups with description + words).\n",
        "    \"\"\"\n",
        "    ds = load_dataset(\"tm21cy/NYT-Connections\")\n",
        "    if split not in ds:\n",
        "        split = list(ds.keys())[0]\n",
        "    return ds[split]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "62483b82",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "puzzles: 652\n"
          ]
        }
      ],
      "source": [
        "hf_split = load_connections_from_hf()\n",
        "print(\"puzzles:\", len(hf_split))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0dcabcf2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Puzzle date: 2024-06-03 00:00:00\n",
            "All words: ['LASER', 'PLUCK', 'THREAD', 'WAX', 'COIL', 'SPOOL', 'WIND', 'WRAP', 'HONEYCOMB', 'ORGANISM', 'SOLAR PANEL', 'SPREADSHEET', 'BALL', 'MOVIE', 'SCHOOL', 'VITAMIN']\n",
            "\n",
            "Predicted groups:\n",
            "['LASER', 'WAX', 'COIL', 'SPOOL']\n",
            "['SPREADSHEET', 'BALL', 'MOVIE', 'SCHOOL']\n",
            "['PLUCK', 'WIND', 'HONEYCOMB', 'VITAMIN']\n",
            "['THREAD', 'WRAP', 'ORGANISM', 'SOLAR PANEL']\n",
            "\n",
            "Gold groups:\n",
            "REMOVE, AS BODY HAIR -> ['LASER', 'PLUCK', 'THREAD', 'WAX']\n",
            "TWIST AROUND -> ['COIL', 'SPOOL', 'WIND', 'WRAP']\n",
            "THINGS MADE OF CELLS -> ['HONEYCOMB', 'ORGANISM', 'SOLAR PANEL', 'SPREADSHEET']\n",
            "B-___ -> ['BALL', 'MOVIE', 'SCHOOL', 'VITAMIN']\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "from torch.nn.functional import normalize\n",
        "\n",
        "\n",
        "def group_similarity(embeddings: torch.Tensor) -> float:\n",
        "    \"\"\"Average pairwise cosine similarity inside a group (embeddings: [4, hidden]).\"\"\"\n",
        "    X = normalize(embeddings, dim=1)\n",
        "    sims = X @ X.T\n",
        "    n = sims.size(0)\n",
        "    mask = ~torch.eye(n, dtype=bool)\n",
        "    sims = sims[mask]\n",
        "    return float(sims.mean())\n",
        "\n",
        "\n",
        "def solve_puzzle(words16: list[str]) -> list[list[str]]:\n",
        "    \"\"\"Given 16 words from one Connections puzzle, greedily form 4 groups of 4 by max avg similarity.\"\"\"\n",
        "    if len(words16) != 16:\n",
        "        raise ValueError(f\"Expected 16 words, got {len(words16)}\")\n",
        "\n",
        "    # Pre-embed all words once\n",
        "    vecs = torch.stack([embed_phrase(w) for w in words16], dim=0)\n",
        "\n",
        "    remaining = list(range(16))\n",
        "    groups_idx: list[list[int]] = []\n",
        "\n",
        "    for _ in range(3):  # first 3 groups; last group is whatever remains\n",
        "        best_score = float(\"-inf\")\n",
        "        best_combo = None\n",
        "        for combo in combinations(remaining, 4):\n",
        "            emb = vecs[list(combo)]\n",
        "            score = group_similarity(emb)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_combo = list(combo)\n",
        "        groups_idx.append(best_combo)\n",
        "        remaining = [i for i in remaining if i not in best_combo]\n",
        "\n",
        "    groups_idx.append(remaining)\n",
        "    return [[words16[i] for i in idxs] for idxs in groups_idx]\n",
        "\n",
        "\n",
        "# Demo on the first puzzle\n",
        "row0 = hf_split[0]\n",
        "words16 = row0[\"words\"]\n",
        "print(\"Puzzle date:\", row0.get(\"date\"))\n",
        "print(\"All words:\", words16)\n",
        "\n",
        "pred_groups = solve_puzzle(words16)\n",
        "print(\"\\nPredicted groups:\")\n",
        "for g in pred_groups:\n",
        "    print(g)\n",
        "\n",
        "print(\"\\nGold groups:\")\n",
        "for ans in row0[\"answers\"]:\n",
        "    print(ans[\"answerDescription\"], \"->\", ans[\"words\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "74136950",
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import permutations\n",
        "\n",
        "\n",
        "def _gold_groups_from_row(row) -> list[list[str]]:\n",
        "    \"\"\"Extract the 4 answer groups (each 4 words) from a puzzle row.\"\"\"\n",
        "    return [list(g.get(\"words\", [])) for g in row.get(\"answers\", []) if len(g.get(\"words\", [])) == 4]\n",
        "\n",
        "\n",
        "def _norm(g: list) -> frozenset:\n",
        "    return frozenset(w.strip() for w in g)\n",
        "\n",
        "\n",
        "def accuracy_zero_one(pred_groups: list[list[str]], gold_groups: list[list[str]]) -> float:\n",
        "    \"\"\"1.0 if predicted groups match gold exactly (as sets of 4 words), else 0.0.\"\"\"\n",
        "    if len(pred_groups) != 4 or len(gold_groups) != 4:\n",
        "        return 0.0\n",
        "    pred_sets = {_norm(g) for g in pred_groups}\n",
        "    gold_sets = {_norm(g) for g in gold_groups}\n",
        "    return 1.0 if pred_sets == gold_sets else 0.0\n",
        "\n",
        "\n",
        "def accuracy_min_swaps(pred_groups: list[list[str]], gold_groups: list[list[str]]) -> float:\n",
        "    \"\"\"Minimum number of 1-for-1 word swaps between groups to turn predicted into gold.\n",
        "\n",
        "    Matches pred groups to gold groups (best bijection), counts misplaced words, returns ceil(misplaced/2).\n",
        "    \"\"\"\n",
        "    if len(pred_groups) != 4 or len(gold_groups) != 4:\n",
        "        return float(\"inf\")\n",
        "    pred_sets = [_norm(g) for g in pred_groups]\n",
        "    gold_sets = [_norm(g) for g in gold_groups]\n",
        "    best_misplaced = 16\n",
        "    for perm in permutations(range(4)):\n",
        "        misplaced = 0\n",
        "        for i in range(4):\n",
        "            j = perm[i]\n",
        "            misplaced += 4 - len(pred_sets[i] & gold_sets[j])\n",
        "        best_misplaced = min(best_misplaced, misplaced)\n",
        "    return (best_misplaced + 1) // 2  # min 1-1 swaps: each swap fixes 2 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b8f64eaa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zero-one accuracy: 0.0000  (n=10, requested=10)\n",
            "Mean 1-1 swaps to correct: 3.90  (n=10)\n"
          ]
        }
      ],
      "source": [
        "def evaluate(split, metric_fn=None, solver_fn=None, max_samples=None):\n",
        "    \"\"\"Run solver on every puzzle and aggregate metric. Plug in a custom metric via metric_fn.\n",
        "\n",
        "    metric_fn(pred_groups, gold_groups) -> float (e.g. 0/1 or partial score).\n",
        "    solver_fn(words16) -> list[list[str]] (default: solve_puzzle).\n",
        "    \"\"\"\n",
        "    if metric_fn is None:\n",
        "        metric_fn = accuracy_zero_one\n",
        "    if solver_fn is None:\n",
        "        solver_fn = solve_puzzle\n",
        "\n",
        "    scores = []\n",
        "    n = len(split) if max_samples is None else min(max_samples, len(split))\n",
        "    for i in range(n):\n",
        "        row = split[i]\n",
        "        words16 = row.get(\"words\", [])\n",
        "        if len(words16) != 16:\n",
        "            continue\n",
        "        gold = _gold_groups_from_row(row)\n",
        "        if len(gold) != 4:\n",
        "            continue\n",
        "        pred = solver_fn(words16)\n",
        "        scores.append(metric_fn(pred, gold))\n",
        "\n",
        "    return sum(scores) / len(scores) if scores else 0.0, len(scores)\n",
        "\n",
        "\n",
        "N_EVAL = 10\n",
        "acc, n_eval = evaluate(hf_split, metric_fn=accuracy_zero_one, max_samples=N_EVAL)\n",
        "mean_swaps, _ = evaluate(hf_split, metric_fn=accuracy_min_swaps, max_samples=N_EVAL)\n",
        "print(f\"Zero-one accuracy: {acc:.4f}  (n={n_eval}, requested={N_EVAL})\")\n",
        "print(f\"Mean 1-1 swaps to correct: {mean_swaps:.2f}  (n={n_eval})\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs175",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
