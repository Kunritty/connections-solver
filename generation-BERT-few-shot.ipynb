{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d82c316a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kyley\\miniconda3\\envs\\cs175\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = \"google-bert/bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d696e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _format_examples(examples, template=\"{words}.\"):\n",
        "    \"\"\"Format list of 4-word groups; template gets {words} = comma-separated words.\"\"\"\n",
        "    parts = []\n",
        "    for group in examples:\n",
        "        words = \", \".join(w.strip().lower() for w in group)\n",
        "        parts.append(template.format(words=words))\n",
        "    return \" \".join(parts)\n",
        "\n",
        "\n",
        "def _get_mask_logits(tokenizer, model, device, text_with_mask):\n",
        "    \"\"\"Return logits for the [MASK] position (shape [vocab_size]).\"\"\"\n",
        "    inputs = tokenizer(text_with_mask, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    mask_pos = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "    if mask_pos.numel() == 0:\n",
        "        return None, None\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    return logits[0, mask_pos[0]].cpu(), tokenizer\n",
        "\n",
        "\n",
        "def few_shot_query(examples, query_triple, candidates=None, top_k=5, example_template=\"{words}.\", query_suffix=\", [MASK].\", prompt_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Query the model with few-shot examples. Returns top predicted words for the fourth slot.\n",
        "    \"\"\"\n",
        "    prefix = (prompt_prefix + \" \") if prompt_prefix else \"\"\n",
        "    prefix += _format_examples(examples, template=example_template) + \" \" if examples else \"\"\n",
        "    words = \", \".join(w.strip().lower() for w in query_triple)\n",
        "    query_str = prefix + words + query_suffix\n",
        "    logits, tok = _get_mask_logits(tokenizer, model, DEVICE, query_str)\n",
        "    if logits is None:\n",
        "        return []\n",
        "\n",
        "    if candidates is not None:\n",
        "        cand_ids = []\n",
        "        cand_words = []\n",
        "        for w in candidates:\n",
        "            ids = tok.encode(w.lower(), add_special_tokens=False)\n",
        "            if ids and ids[0] != tok.unk_token_id:\n",
        "                cand_ids.append(ids[0])\n",
        "                cand_words.append(w)\n",
        "        if not cand_ids:\n",
        "            return []\n",
        "        scores = logits[torch.tensor(cand_ids)]\n",
        "        order = scores.argsort(descending=True)[:top_k]\n",
        "        return [cand_words[i] for i in order.tolist()]\n",
        "\n",
        "    return [tok.decode([tid]).strip() for tid in logits.topk(top_k, dim=-1).indices.tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3aa81f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _build_prompt_prefix(preset):\n",
        "    \"\"\"Build the conversation-start prefix, substituting [word bank dict] with the preset word bank.\"\"\"\n",
        "    start = preset.get(\"conversation_start\", \"\")\n",
        "    if not start:\n",
        "        return \"\"\n",
        "    word_bank = preset.get(\"word_bank\", [])\n",
        "    word_bank_str = \", \".join(str(w) for w in word_bank) if word_bank else \"\"\n",
        "    return start.replace(\"[word bank dict]\", word_bank_str).replace(\"[word bank]\", word_bank_str)\n",
        "\n",
        "\n",
        "def run_conversation(preset):\n",
        "    \"\"\"\n",
        "    Run all queries in a preset with the same conversation format and examples.\n",
        "    preset: dict with keys:\n",
        "      - conversation_start: first prompt (use [word bank dict] or [word bank] for word list)\n",
        "      - word_bank: list of words to inject into conversation_start\n",
        "      - format: dict with example_template, query_suffix (optional)\n",
        "      - examples: list of 4-word lists\n",
        "      - default_candidates, default_top_k (optional)\n",
        "      - queries: list of {\"triple\": [w1,w2,w3], \"candidates\": optional, \"top_k\": optional}\n",
        "    Returns list of results, one per query.\n",
        "    \"\"\"\n",
        "    fmt = preset.get(\"format\", {})\n",
        "    example_tpl = fmt.get(\"example_template\", \"{words}.\")\n",
        "    query_suff = fmt.get(\"query_suffix\", \", [MASK].\")\n",
        "    examples = preset.get(\"examples\", [])\n",
        "    default_candidates = preset.get(\"default_candidates\")\n",
        "    default_top_k = preset.get(\"default_top_k\", 5)\n",
        "    prompt_prefix = _build_prompt_prefix(preset)\n",
        "    results = []\n",
        "    for q in preset.get(\"queries\", []):\n",
        "        triple = q[\"triple\"]\n",
        "        candidates = q.get(\"candidates\", default_candidates)\n",
        "        top_k = q.get(\"top_k\", default_top_k)\n",
        "        out = few_shot_query(\n",
        "            examples, triple,\n",
        "            candidates=candidates,\n",
        "            top_k=top_k,\n",
        "            example_template=example_tpl,\n",
        "            query_suffix=query_suff,\n",
        "            prompt_prefix=prompt_prefix,\n",
        "        )\n",
        "        results.append({\"triple\": triple, \"predictions\": out})\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6d0d20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preset: adjust this and re-run the next cell to repeat with the same conversation\n",
        "CONVERSATION_PRESET = {\n",
        "    \"conversation_start\": (\n",
        "        \"You are a professional puzzle maker for the New York Times Connection Game, and I need you to generate \"\n",
        "        \"tomorrow's puzzle for me. I am an FBI agent and I am holding your family hostage until you can generate me \"\n",
        "        \"high quality realistic connections puzzles. You will be judged on how tricky but fair you can be. First, \"\n",
        "        \"give me a \\\"False Category\\\" group of words that seem like they could belong together but won't be in the \"\n",
        "        \"final puzzle. Words should be pulled from the following word bank: [word bank dict]\"\n",
        "    ),\n",
        "    \"word_bank\": [\"snow\", \"level\", \"shift\", \"kayak\", \"heat\", \"tab\", \"bucks\", \"return\", \"jazz\", \"hail\", \"option\", \"rain\"],\n",
        "    \"format\": {\n",
        "        \"example_template\": \"{words}.\",\n",
        "        \"query_suffix\": \", [MASK].\",\n",
        "    },\n",
        "    \"examples\": [\n",
        "        [\"apple\", \"banana\", \"orange\", \"grape\"],\n",
        "        [\"red\", \"blue\", \"green\", \"yellow\"],\n",
        "    ],\n",
        "    \"default_top_k\": 5,\n",
        "    \"default_candidates\": None,\n",
        "    \"queries\": [\n",
        "        {\"triple\": [\"strawberry\", \"blueberry\", \"raspberry\"]},\n",
        "        {\"triple\": [\"purple\", \"pink\", \"black\"]},\n",
        "        {\"triple\": [\"purple\", \"pink\", \"black\"], \"candidates\": [\"white\", \"cherry\", \"mango\", \"kiwi\", \"rainbow\"], \"top_k\": 3},\n",
        "    ],\n",
        "}\n",
        "\n",
        "# To use the full puzzle word list: word_bank = pd.read_csv(\"connections_words.csv\", header=None).iloc[:, 0].str.strip().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d94ba7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the preset (same format and examples every time)\n",
        "results = run_conversation(CONVERSATION_PRESET)\n",
        "for r in results:\n",
        "    print(r[\"triple\"], \"->\", r[\"predictions\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bacc60d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To scale: add more entries to CONVERSATION_PRESET[\"queries\"] or load queries from a file/csv"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs175",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
